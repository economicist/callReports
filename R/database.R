#' Create a `function` that opens an SQLite connection on command.
#' 
#' `db_connector_sqlite()` returns a `function` that allows an SQLite connection
#' to be opened whenever necessary by other functions in this package.
#' 
#' @param sqlite_db_path The path to an SQLite database file. Must be in an
#' existing directory. The file will be created if it does not exist.
#' @return A `function` that opens a connection to the database given in
#' `sqlite_db_path`. It should be passed to other functions without the `()`
#' @importFrom magrittr %>%
#' @importFrom DBI dbConnect
#' @importFrom glue glue
#' @export
#' @examples
#' db_connector_sqlite('./db/ffiec.sqlite')
db_connector_sqlite <- function(sqlite_db_path, overwrite = FALSE) {
  dir_name  <- dirname(sqlite_db_path)
  dir_name  <- ifelse(dir_name == '.', getwd(), dir_name)
  file_name <- basename(sqlite_db_path)
  
  if (!dir.exists(dir_name)) {
    stop(glue('Directory `{dir_name}` does not exist. Confirm or create it.'))
  }
  
  if (file.exists(sqlite_db_path)) {
    journal_path <- glue('{sqlite_db_path}-journal')
    if (file.exists(journal_path)) {
      cat(glue('Database lock file {journal_path} detected.'), '\n')
      cat('This can be because there is an active transaction being performed\n')
      cat('on the database, or perhaps because a transaction was interrupted.\n')
      confirm_and_delete(journal_path)
    }
    if (overwrite) confirm_and_delete(sqlite_db_path)
  } else {
    cat(glue('`{file_name}` does not exist in directory `{dir_name}`'), '\n')
    cat('Attempting to create it...\n')
    tryCatch(callReports::create_new_sqlite_db(sqlite_db_path), error = stop)
  }
  
  function() dbConnect(RSQLite::SQLite(), sqlite_db_path)
}

#' Create a new SQLite database to extract data into
#' 
#' If the SQLite database filename specified in `sqlite_db_path` already exists
#' and `overwrite` is set to `FALSE`, the user will be prompted to explicitly
#' permit overwriting it it.
#' 
#' `db_connector_sqlite(sqlite_db_path)` requires the path to a valid existing
#' SQLite database file. If one does not exist, one should be created using this
#' function before proceeding to extract data.
#' 
#' @param sqlite_db_path A path containing at least a valid SQLite filename. It
#' will be created in the current working directory if is not specified as part
#' of the filename.
#' @return A `function` that opens a connection to the newly created SQLite
#' database on demand
#' @importFrom DBI dbConnect dbDisconnect
#' @importFrom glue glue
#' @importFrom rlog log_info
#' @export
#' @examples
#' # Create a new database file:
#' create_new_sqlite_db('./zips-ffiec/ffiec.sqlite')
create_new_sqlite_db <- function(sqlite_db_path) {
  # If file exists, ask for permission to overwrite. Exit if permission denied.
  callReports::confirm_and_delete(sqlite_db_path)
  
  # Try to open a connection to a new SQLite database at `sqlite_db_path`.
  # Stop execution if there's an error. Announce success otherwise.
  tryCatch({
    db_conn <- dbConnect(RSQLite::SQLite(), sqlite_db_path)
    dbDisconnect(db_conn)
  },
  error = stop)
  log_info(glue('New SQLite database `{sqlite_db_path}` created.'))
  cat('\n')
}

#' Write extracted FFIEC schedule data to a database
#'
#' `write_ffiec_schedule()` writes the observation, codebook, and summary data
#' generated by `extract_ffiec_schedule()` to the database whose connector is
#' given by `db_connector`.
#'
#' Uses a database "transaction" to write all three tables worth of data in one
#' go and only save the data if all of it succeeds. Either everything is written
#' to the database successfully, or nothing is. This prevents duplicate data
#' being entered into the database in case one reattempts to enter a schedule
#' after a hypothetical failed attempt that gets interrupted mid-write. Using a
#' transaction allows us to respond to any failure with an error by "rolling
#' back" (undoing) any new writes to the database and returning. If successful,
#' however, we "commit" (finalize) the changes to the database so that they'll
#' be visible in future queries.
#'
#' @param db_connector A `function` created by one of the `db_connector_*()`
#' functions found in this package. It should be passed without the `()`
#' @param tbl_name The name of the table you're writing, which should be a
#' valid schedule code.
#' @param df_obs A `tibble` containing the observations found in the extracted
#' schedule file, pivoted to long form.
#' `VALUE`)
#' @param df_codes A `tibble` containing the codebook information associated
#' with the extracted schedule file.
#' @param df_summ A `tibble` containing information about how many `IDRSSD` 
#' values are associated with each `VAR_NAME` pair in the schedule
#' @importFrom DBI dbExecute dbExistsTable dbCreateTable dbWriteTable
#' @importFrom DBI dbBegin dbCommit dbRollback
#' @importFrom glue glue
#' @importFrom rlog log_info log_fatal
#' @export
write_ffiec_schedule <- 
  function(db_connector, tbl_name, df_obs, df_codes, df_summ) {
    db_conn <- db_connector()
    dbBegin(db_conn)
    tryCatch({
      dbWriteTable(db_conn, 'CODEBOOK', df_codes, append = TRUE)
      log_info(glue('Writing {nrow(df_obs)} observations to the database...'))
      if (!dbExistsTable(db_conn, tbl_name)) {
        # `IDRSSD` and `QUARTER_ID` can both be interpreted as integers, so
        # force the database to acknowledge them as such.
        dbCreateTable(conn   = db_conn, 
                      name   = tbl_name, 
                      fields = c(IDRSSD      = 'INTEGER',
                                 QUARTER_ID  = 'INTEGER',
                                 VAR_CODE_ID = 'INTEGER',
                                 VALUE       = 'TEXT'))
      }
      dbWriteTable(db_conn, tbl_name, df_obs, append = TRUE)
      dbWriteTable(db_conn, 'SUMMARY', df_summ, append = TRUE)
      dbCommit(db_conn)
    },
    warning = function(w) {
      warning(w)
    },
    error = function(e) {
      dbRollback(db_conn)
      log_fatal('Error writing data to the database. No observations added:')
      stop(e)
    },
    finally = {
      dbDisconnect(db_conn)
      cat('\n')
    })
  }

#' Add discovered FFIEC variable names to an index table
#' 
#' `write_ffiec_varcodes()` takes a list of variable codes and adds each of them
#' to a database table containing only a pairing between an integer ID and the
#' variable code. If the variable code is already in the table, it is skipped.
#' If it is not, it is automatically assigned an integer ID value in the order 
#' in which it is added.
#' 
#' Given the numerous variables in the source data, this library pivots the data
#' into long form before writing to the database. This offers the benefit of
#' allowing each table in the database to have a predictable description and 
#' prevent issues with exceeding the native maximum column support of many
#' database engines. However, it 
#'
#' @param db_connector 
#' @param var_codes 
#' @importFrom DBI dbExistsTable dbExecute dbWriteTable dbDisconnect
#' @importFrom tibble tibble
#' @export
write_ffiec_varcodes <- function(db_connector, var_codes) {
  `%not_in%` <- Negate(`%in%`)
  db_conn <- db_connector()
  if (!dbExistsTable(db_conn, 'VAR_CODES')) {
    tbl_gen_query <- 
      'CREATE TABLE VAR_CODES' %>%
      paste('(ID INTEGER PRIMARY KEY AUTOINCREMENT, VAR_CODE TEXT UNIQUE)')
    dbExecute(db_conn, tbl_gen_query)
  }
  existing_codes <- 
    dbReadTable(db_conn, 'VAR_CODES') %>%
    select(VAR_CODE) %>% 
    collect() %>% 
    getElement('VAR_CODE')
  new_var_codes <- 
    tibble(ID = rep(NA, length(var_codes)),
           VAR_CODE = var_codes) %>%
    filter(VAR_CODE %not_in% existing_codes)
  dbWriteTable(db_conn, 'VAR_CODES', new_var_codes, append = TRUE)
  dbDisconnect(db_conn)
}